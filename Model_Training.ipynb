{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e7f62d-0a88-4974-887c-66d7854f9203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "     print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba35f01-7dba-4326-bf17-f1b7a938933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060\n",
      "Found 1 dataset files to process...\n",
      "--> Successfully loaded and processed 'cleaned_spam_dataset.csv', adding 16205 rows.\n",
      "\n",
      "Total combined rows: 16,205\n",
      "Rows after removing duplicate text entries: 16,205\n",
      "Final dataset shuffled and ready for training.\n",
      "\n",
      "--- Final Class Distribution ---\n",
      "Ham (0):  14,016\n",
      "Spam (1): 2,189\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--- Standardized DataFrame Head ---\n",
      "   label                                               text\n",
      "0      0         Sorry, I'll call later  &lt;#&gt; mins\\r\\n\n",
      "1      0  Thts god's gift for birds as humans hav some n...\n",
      "2      0       ['K..k...from tomorrow onwards started ah?']\n",
      "3      0  NO GIFTS!! You trying to get me to throw mysel...\n",
      "4      0     With my sis lor... We juz watched italian job.\n",
      "5      0  ['\"How are you, my Love ? Are you with your br...\n",
      "6      0                   ['what is your account number?']\n",
      "7      0                                Yup ok thanx...\\r\\n\n",
      "8      0  O we cant see if we can join denis and mina? O...\n",
      "9      0                ['Customer place i will call you.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "\n",
    "#Configuration & Hyperparameters\n",
    "MODEL_NAME = './local-bert-base-uncased'\n",
    "DATASET_DIRECTORY = './datasets/'\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "ADAM_EPSILON = 1e-8\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#Device Setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Collects all CSV files from the given directory, normalizes column names and labels,\n",
    "# merges them into a single dataset, removes duplicate rows, and randomly shuffles the final result.\n",
    "def load_and_standardize_datasets(path):\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    if not all_files:\n",
    "        print(f\"Error: No CSV files were found in the directory '{path}'.\")\n",
    "        print(\"Please make sure your CSV files are inside the 'datasets' folder.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Found {len(all_files)} dataset files to process...\")\n",
    "\n",
    "    df_list = []\n",
    "    for filename in all_files:\n",
    "        try:\n",
    "            #Attempt to load with common encodings\n",
    "            df = pd.read_csv(filename, encoding='latin-1')\n",
    "\n",
    "            #Standardize Column Names\n",
    "            column_rename_map = {\n",
    "                'v1': 'label', 'v2': 'text',\n",
    "                'Category': 'label', 'Message': 'text',\n",
    "                'CLASS': 'label', 'CONTENT': 'text'\n",
    "            }\n",
    "            df = df.rename(columns=lambda c: c.strip().lower()).rename(columns=column_rename_map)\n",
    "\n",
    "            if 'label' not in df.columns or 'text' not in df.columns:\n",
    "                print(f\"--> Skipping file: '{os.path.basename(filename)}'. Could not find required 'label' and 'text' columns.\")\n",
    "                continue\n",
    "\n",
    "            df = df[['label', 'text']]\n",
    "\n",
    "            #Standardize Labels\n",
    "            label_map = {\n",
    "                'ham': 0, 'spam': 1,\n",
    "                '0': 0, '1': 1,\n",
    "                'normal': 0,\n",
    "                'legitimate': 0\n",
    "            }\n",
    "            df['label'] = df['label'].astype(str).str.lower().map(label_map)\n",
    "\n",
    "            df.dropna(inplace=True)\n",
    "            df['label'] = df['label'].astype(int)\n",
    "\n",
    "            df_list.append(df)\n",
    "            print(f\"--> Successfully loaded and processed '{os.path.basename(filename)}', adding {len(df)} rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"--> Error processing file '{os.path.basename(filename)}': {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"\\nError: No data could be loaded from any of the files. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    master_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"\\nTotal combined rows: {len(master_df):,}\")\n",
    "\n",
    "    master_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "    print(f\"Rows after removing duplicate text entries: {len(master_df):,}\")\n",
    "\n",
    "    master_df = master_df.sample(frac=1).reset_index(drop=True)\n",
    "    print(\"Final dataset shuffled and ready for training.\")\n",
    "    print(\"\\n--- Final Class Distribution ---\")\n",
    "\n",
    "    class_counts = master_df['label'].value_counts()\n",
    "    \n",
    "    ham_count = class_counts.get(0, 0)\n",
    "    spam_count = class_counts.get(1, 0)\n",
    "    \n",
    "    print(f\"Ham (0):  {ham_count:,}\")\n",
    "    print(f\"Spam (1): {spam_count:,}\")\n",
    "    print(\"--------------------------------\\n\")\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    return master_df\n",
    "\n",
    "\n",
    "#Execution\n",
    "df = load_and_standardize_datasets(DATASET_DIRECTORY)\n",
    "print(\"\\n--- Standardized DataFrame Head ---\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401d0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates accuracy by comparing predicted class indices with true labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "#Converts elapsed time in seconds into a formatted hh:mm:ss string\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a889ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading and Preparing Data ---\n",
      "Found 1 dataset files to process...\n",
      "--> Successfully loaded and processed 'cleaned_spam_dataset.csv', adding 16205 rows.\n",
      "\n",
      "Total combined rows: 16,205\n",
      "Rows after removing duplicate text entries: 16,205\n",
      "Final dataset shuffled and ready for training.\n",
      "\n",
      "--- Final Class Distribution ---\n",
      "Ham (0):  14,016\n",
      "Spam (1): 2,189\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--- Tokenizing Data ---\n",
      "Loading BERT tokenizer from local path: './local-bert-base-uncased'...\n"
     ]
    }
   ],
   "source": [
    "#Load and Prepare Data\n",
    "print(\"\\n--- Loading and Preparing Data ---\")\n",
    "df = load_and_standardize_datasets(DATASET_DIRECTORY)\n",
    "\n",
    "\n",
    "#Extract the text and labels into arrays\n",
    "sentences = df.text.values\n",
    "labels = df.label.values\n",
    "\n",
    "\n",
    "#Tokenization (Initialize BERT tokenizer)\n",
    "print(f\"\\n--- Tokenizing Data ---\")\n",
    "print(f\"Loading BERT tokenizer from local path: '{MODEL_NAME}'...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "#Lists to hold token IDs and attention masks for each sentence\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "\n",
    "#Convert each sentence into token IDs and attention masks\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=MAX_LEN,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt',\n",
    "                   )\n",
    "    \n",
    "    \n",
    "     #Save token IDs and attention mask\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "\n",
    "#Concatenate all token IDs and attention masks into single tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "\n",
    "#Convert labels into a tensor\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f080451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating DataLoaders ---\n",
      "[ 14,584 ] training samples\n",
      "[ 1,621 ] validation samples\n"
     ]
    }
   ],
   "source": [
    "# 3. Create Datasets and DataLoaders\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "\n",
    "\n",
    "#Wrap input IDs, attention masks, and labels into a single dataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "\n",
    "#Split dataset into training (90%) and validation (10%) sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "#Show dataset sizes\n",
    "print(f'[ {train_size:,} ] training samples')\n",
    "print(f'[ {val_size:,} ] validation samples')\n",
    "\n",
    "\n",
    "#DataLoader for training set (random sampling for shuffling each epoch)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "#DataLoader for validation set (sequential sampling, no shuffling)\n",
    "validation_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019d1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./local-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Pre-trained Model ---\n",
      "Loading BERT model from local path: './local-bert-base-uncased'...\n"
     ]
    }
   ],
   "source": [
    "#Load Pre-trained Model\n",
    "print(f\"\\n--- Loading Pre-trained Model ---\")\n",
    "print(f\"Loading BERT model from local path: '{MODEL_NAME}'...\")\n",
    "\n",
    "\n",
    "#Load BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "\n",
    "#Move model to the selected device (CPU or GPU)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#Setup Optimizer and Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=ADAM_EPSILON)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c2795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: Starting Training ---\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    912.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    912.    Elapsed: 0:00:32.\n",
      "  Batch   120  of    912.    Elapsed: 0:00:48.\n",
      "  Batch   160  of    912.    Elapsed: 0:01:03.\n",
      "  Batch   200  of    912.    Elapsed: 0:01:19.\n",
      "  Batch   240  of    912.    Elapsed: 0:01:34.\n",
      "  Batch   280  of    912.    Elapsed: 0:01:50.\n",
      "  Batch   320  of    912.    Elapsed: 0:02:06.\n",
      "  Batch   360  of    912.    Elapsed: 0:02:21.\n",
      "  Batch   400  of    912.    Elapsed: 0:02:37.\n",
      "  Batch   440  of    912.    Elapsed: 0:02:52.\n",
      "  Batch   480  of    912.    Elapsed: 0:03:08.\n",
      "  Batch   520  of    912.    Elapsed: 0:03:23.\n",
      "  Batch   560  of    912.    Elapsed: 0:03:39.\n",
      "  Batch   600  of    912.    Elapsed: 0:03:54.\n",
      "  Batch   640  of    912.    Elapsed: 0:04:10.\n",
      "  Batch   680  of    912.    Elapsed: 0:04:25.\n",
      "  Batch   720  of    912.    Elapsed: 0:04:41.\n",
      "  Batch   760  of    912.    Elapsed: 0:04:57.\n",
      "  Batch   800  of    912.    Elapsed: 0:05:12.\n",
      "  Batch   840  of    912.    Elapsed: 0:05:28.\n",
      "  Batch   880  of    912.    Elapsed: 0:05:43.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:05:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation Loss: 0.01\n",
      "  Validation took: 0:00:12\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    912.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    912.    Elapsed: 0:00:31.\n",
      "  Batch   120  of    912.    Elapsed: 0:00:46.\n",
      "  Batch   160  of    912.    Elapsed: 0:01:02.\n",
      "  Batch   200  of    912.    Elapsed: 0:01:18.\n",
      "  Batch   240  of    912.    Elapsed: 0:01:33.\n",
      "  Batch   280  of    912.    Elapsed: 0:01:49.\n",
      "  Batch   320  of    912.    Elapsed: 0:02:04.\n",
      "  Batch   360  of    912.    Elapsed: 0:02:20.\n",
      "  Batch   400  of    912.    Elapsed: 0:02:35.\n",
      "  Batch   440  of    912.    Elapsed: 0:02:51.\n",
      "  Batch   480  of    912.    Elapsed: 0:03:06.\n",
      "  Batch   520  of    912.    Elapsed: 0:03:22.\n",
      "  Batch   560  of    912.    Elapsed: 0:03:37.\n",
      "  Batch   600  of    912.    Elapsed: 0:03:53.\n",
      "  Batch   640  of    912.    Elapsed: 0:04:09.\n",
      "  Batch   680  of    912.    Elapsed: 0:04:24.\n",
      "  Batch   720  of    912.    Elapsed: 0:04:40.\n",
      "  Batch   760  of    912.    Elapsed: 0:04:55.\n",
      "  Batch   800  of    912.    Elapsed: 0:05:11.\n",
      "  Batch   840  of    912.    Elapsed: 0:05:26.\n",
      "  Batch   880  of    912.    Elapsed: 0:05:42.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:05:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation Loss: 0.00\n",
      "  Validation took: 0:00:12\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    912.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    912.    Elapsed: 0:00:31.\n",
      "  Batch   120  of    912.    Elapsed: 0:00:46.\n",
      "  Batch   160  of    912.    Elapsed: 0:01:02.\n",
      "  Batch   200  of    912.    Elapsed: 0:01:18.\n",
      "  Batch   240  of    912.    Elapsed: 0:01:33.\n",
      "  Batch   280  of    912.    Elapsed: 0:01:49.\n",
      "  Batch   320  of    912.    Elapsed: 0:02:04.\n",
      "  Batch   360  of    912.    Elapsed: 0:02:20.\n",
      "  Batch   400  of    912.    Elapsed: 0:02:35.\n",
      "  Batch   440  of    912.    Elapsed: 0:02:51.\n",
      "  Batch   480  of    912.    Elapsed: 0:03:07.\n",
      "  Batch   520  of    912.    Elapsed: 0:03:22.\n",
      "  Batch   560  of    912.    Elapsed: 0:03:38.\n",
      "  Batch   600  of    912.    Elapsed: 0:03:53.\n",
      "  Batch   640  of    912.    Elapsed: 0:04:09.\n",
      "  Batch   680  of    912.    Elapsed: 0:04:25.\n",
      "  Batch   720  of    912.    Elapsed: 0:04:40.\n",
      "  Batch   760  of    912.    Elapsed: 0:04:56.\n",
      "  Batch   800  of    912.    Elapsed: 0:05:12.\n",
      "  Batch   840  of    912.    Elapsed: 0:05:27.\n",
      "  Batch   880  of    912.    Elapsed: 0:05:43.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:05:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation Loss: 0.00\n",
      "  Validation took: 0:00:12\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    912.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    912.    Elapsed: 0:00:31.\n",
      "  Batch   120  of    912.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    912.    Elapsed: 0:01:02.\n",
      "  Batch   200  of    912.    Elapsed: 0:01:18.\n",
      "  Batch   240  of    912.    Elapsed: 0:01:34.\n",
      "  Batch   280  of    912.    Elapsed: 0:01:49.\n",
      "  Batch   320  of    912.    Elapsed: 0:02:05.\n",
      "  Batch   360  of    912.    Elapsed: 0:02:20.\n",
      "  Batch   400  of    912.    Elapsed: 0:02:36.\n",
      "  Batch   440  of    912.    Elapsed: 0:02:52.\n",
      "  Batch   480  of    912.    Elapsed: 0:03:07.\n",
      "  Batch   520  of    912.    Elapsed: 0:03:23.\n",
      "  Batch   560  of    912.    Elapsed: 0:03:39.\n",
      "  Batch   600  of    912.    Elapsed: 0:03:54.\n",
      "  Batch   640  of    912.    Elapsed: 0:04:10.\n",
      "  Batch   680  of    912.    Elapsed: 0:04:25.\n",
      "  Batch   720  of    912.    Elapsed: 0:04:41.\n",
      "  Batch   760  of    912.    Elapsed: 0:04:57.\n",
      "  Batch   800  of    912.    Elapsed: 0:05:12.\n",
      "  Batch   840  of    912.    Elapsed: 0:05:28.\n",
      "  Batch   880  of    912.    Elapsed: 0:05:44.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:05:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 1.00\n",
      "  Validation Loss: 0.00\n",
      "  Validation took: 0:00:12\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:24:29 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "#Track total training time\n",
    "total_t0 = time.time()\n",
    "\n",
    "\n",
    "#Store training statistics (loss, accuracy, time per epoch, etc.)\n",
    "training_stats = []\n",
    "\n",
    "\n",
    "#Loop through each epoch\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {EPOCHS} ========\")\n",
    "    print('Training...')\n",
    "    \n",
    "    \n",
    "    #Track epoch start time and training loss\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    #Put model into training mode\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    #--- Training Phase ---\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        #Print progress every 40 batches\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed}.')\n",
    "\n",
    "        \n",
    "        #Unpack training batch and move tensors to GPU/CPU device\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        \n",
    "        #Reset gradients before each step\n",
    "        model.zero_grad()\n",
    "        \n",
    "        \n",
    "        #Forward pass → Compute loss & predictions\n",
    "        result = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels, \n",
    "            return_dict=True\n",
    "            )\n",
    "        \n",
    "        \n",
    "        #Extract training loss\n",
    "        loss = result.loss\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        #Backward pass → compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # Clip gradients to prevent exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        \n",
    "        #Update model weights and learning rate according to scheduler\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "    #Calculate average loss over training batches\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    \n",
    "    \n",
    "    print(f\"\\n  Average training loss: {avg_train_loss:.2f}\")\n",
    "    print(f\"  Training epoch took: {training_time}\")\n",
    "    \n",
    "    \n",
    "    #Validation Phase\n",
    "    print(\"\\nRunning Validation...\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    \n",
    "    #Put model into evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    #Track validation metrics\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Move validation batch to device\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        \n",
    "        #Disable gradient calculation during validation for efficiency\n",
    "        with torch.no_grad():\n",
    "            result = model(\n",
    "                b_input_ids, \n",
    "                token_type_ids=None, \n",
    "                attention_mask=b_input_mask, \n",
    "                labels=b_labels, \n",
    "                return_dict=True\n",
    "                )\n",
    "\n",
    "\n",
    "        #Extract loss and logits\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        #Move predictions and labels to CPU for evaluation\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        \n",
    "        # Compute accuracy for this batch\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        \n",
    "    # Compute average validation accuracy & loss\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    \n",
    "    print(f\"  Accuracy: {avg_val_accuracy:.2f}\")\n",
    "    print(f\"  Validation Loss: {avg_val_loss:.2f}\")\n",
    "    print(f\"  Validation took: {validation_time}\")\n",
    "\n",
    "    \n",
    "    #Save stats for this epoch\n",
    "    training_stats.append({\n",
    "        'epoch': epoch_i + 1,\n",
    "        'Training Loss': avg_train_loss,\n",
    "        'Valid. Loss': avg_val_loss,\n",
    "        'Valid. Accuracy.': avg_val_accuracy,\n",
    "        'Training Time': training_time,\n",
    "        'Validation Time': validation_time\n",
    "    })\n",
    "    \n",
    "    \n",
    "#  --- Training Finished ---\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Total training took {format_time(time.time()-total_t0)} (h:mm:ss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2539595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating on Validation Set ---\n",
      "    DONE.\n",
      "\n",
      "Total Accuracy: 0.8260\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " Ham (Class 0)       0.87      0.94      0.90      1419\n",
      "Spam (Class 1)       0.03      0.01      0.02       202\n",
      "\n",
      "      accuracy                           0.83      1621\n",
      "     macro avg       0.45      0.48      0.46      1621\n",
      "  weighted avg       0.77      0.83      0.79      1621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Final Prediction and Accuracy Calculation ---\n",
    "print(\"\\n--- Evaluating on Validation Set ---\")\n",
    "\n",
    "#Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "#Track predictions and true labels across batches\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "\n",
    "#Generate Predictions\n",
    "for batch in validation_dataloader:\n",
    "    #Add batch to GPU/CPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    \n",
    "    #Unpack the inputs\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    \n",
    "    #Disable gradient calculations for efficiency\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #Forward pass, calculate logit predictions\n",
    "        result = model(\n",
    "                        b_input_ids,\n",
    "                       token_type_ids=None,\n",
    "                       attention_mask=b_input_mask,\n",
    "                       return_dict=True\n",
    "                       )\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "    #Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    #Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "#--- Process Predictions and Calculate Metrics ---\n",
    "\n",
    "#Combine the results from all batches\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "#For each sample, pick the label (0 or 1) with the higher score.\n",
    "predicted_labels = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "#Calculate the overall accuracy\n",
    "accuracy = np.sum(predicted_labels == flat_true_labels) / len(flat_true_labels)\n",
    "print(f\"\\nTotal Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "#Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(flat_true_labels, predicted_labels, target_names=['Ham (Class 0)', 'Spam (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cc8c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#--- Plotting training statistics ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#Create a DataFrame from our training statistics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_stats = pd.DataFrame(data=\u001b[43mtraining_stats\u001b[49m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#Use the 'epoch' as the row index\u001b[39;00m\n\u001b[32m      6\u001b[39m df_stats = df_stats.set_index(\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'training_stats' is not defined"
     ]
    }
   ],
   "source": [
    "#--- Plotting training statistics ---\n",
    "#Create a DataFrame from our training statistics\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "#Use the 'epoch' as the row index\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "#Use plot styling from seaborn\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "#Increase the plot size and font size\n",
    "sns.set_theme(font_scale=0.8)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "\n",
    "\n",
    "#Plot the learning curve for Loss\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "#Add titles and labels\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([i for i in range(1, EPOCHS + 1)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Plot the learning curve for Accuracy\n",
    "plt.plot(df_stats['Valid. Accur.'], 'r-o', label=\"Validation Accuracy\")\n",
    "\n",
    "#Label the plot\n",
    "plt.title(\"Validation Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks([i for i in range(1, EPOCHS + 1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debf551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final model to ./model_save/\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "#--- Saving Final Model ---\n",
    "output_dir = './model_save/'\n",
    "\n",
    "#Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#Save trained model (weights + config)\n",
    "print(f\"Saving final model to {output_dir}\")\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "#Save tokenizer (vocabulary + config)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(\"Save complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21cfb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing text: \"Hey everyone! Check out this amazing deal! https://ssww.blog.ss\"\n",
      "------------------------------\n",
      "Prediction: Spam\n",
      "Confidence: \n",
      "  - Ham:  0.03%\n",
      "  - Spam: 99.97%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Path to the directory where the fine-tuned model is saved\n",
    "MODEL_PATH = './model_save/'\n",
    "\n",
    "# IMPORTANT: This must be the same MAX_LEN that you used during training.\n",
    "MAX_LEN = 256\n",
    "\n",
    "def predict_spam(text):\n",
    "    \n",
    "    # --- Device Setup ---\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    #Load Tokenizer and Model\n",
    "    try:\n",
    "        tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "        \n",
    "        #Load the fine-tuned model\n",
    "        model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "        \n",
    "        #Move model to the correct device (GPU or CPU)\n",
    "        model.to(device)\n",
    "\n",
    "        #Set the model to evaluation mode \n",
    "        model.eval()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or tokenizer: {e}\")\n",
    "        return None\n",
    "        \n",
    "    # --- Preprocess the Input Text ---\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',  # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    #Move tensors to the same device as the model\n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "\n",
    "    # --- Make a Prediction ---\n",
    "    #Use torch.no_grad() to disable gradient calculations for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "\n",
    "    # --- Process the Output ---\n",
    "    probabilities = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    prediction_index = torch.argmax(logits, dim=1).item()\n",
    "    labels = ['Ham', 'Spam']\n",
    "    prediction = labels[prediction_index]\n",
    "\n",
    "    #Return a dictionary with the results\n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'confidence': {\n",
    "            'ham': f\"{probabilities[0]*100:.2f}%\",\n",
    "            'spam': f\"{probabilities[1]*100:.2f}%\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "#Define the sentence you want to test\n",
    "test_sentence_spam = \"Hey everyone! Check out this amazing deal! https://ssww.blog.ss\"\n",
    "\n",
    "#Call the prediction function\n",
    "result = predict_spam(test_sentence_spam)\n",
    "\n",
    "#Print the results in a clean format\n",
    "if result:\n",
    "    print(f\"Analyzing text: \\\"{test_sentence_spam}\\\"\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Prediction: {result['prediction']}\")\n",
    "    print(f\"Confidence: \")\n",
    "    print(f\"  - Ham:  {result['confidence']['ham']}\")\n",
    "    print(f\"  - Spam: {result['confidence']['spam']}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
